{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 12 - NETWORKED PROGRAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 The Worldâ€™s Simplest Web Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\r\n",
      "Date: Sat, 06 Apr 2019 11:45:41 GMT\r\n",
      "Server: Apache/2.4.18 (Ubuntu)\r\n",
      "Last-Modified: Sat, 13 May 2017 11:22:22 GMT\r\n",
      "ETag: \"a7-54f6609245537\"\r\n",
      "Accept-Ranges: bytes\r\n",
      "Content-Length: 167\r\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\r\n",
      "Pragma: no-cache\r\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\r\n",
      "Connection: close\r\n",
      "Content-Type: text/plain\r\n",
      "\r\n",
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if len(data) < 1:\n",
    "        break\n",
    "    print(data.decode(),end='')\n",
    "\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 Retrieving an image over HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5120 5120\n",
      "5120 10240\n",
      "2760 13000\n",
      "5120 18120\n",
      "5120 23240\n",
      "5120 28360\n",
      "5120 33480\n",
      "5120 38600\n",
      "400 39000\n",
      "5120 44120\n",
      "5120 49240\n",
      "5120 54360\n",
      "2840 57200\n",
      "5120 62320\n",
      "5120 67440\n",
      "5120 72560\n",
      "5120 77680\n",
      "5120 82800\n",
      "5120 87920\n",
      "3080 91000\n",
      "5120 96120\n",
      "80 96200\n",
      "5120 101320\n",
      "80 101400\n",
      "5120 106520\n",
      "5120 111640\n",
      "5120 116760\n",
      "5120 121880\n",
      "5120 127000\n",
      "5120 132120\n",
      "5120 137240\n",
      "5120 142360\n",
      "1940 144300\n",
      "5120 149420\n",
      "5120 154540\n",
      "5120 159660\n",
      "5120 164780\n",
      "5120 169900\n",
      "5120 175020\n",
      "5120 180140\n",
      "5120 185260\n",
      "5120 190380\n",
      "5120 195500\n",
      "5120 200620\n",
      "5120 205740\n",
      "3560 209300\n",
      "5120 214420\n",
      "5120 219540\n",
      "5120 224660\n",
      "5120 229780\n",
      "828 230608\n",
      "Header length 394\n",
      "HTTP/1.1 200 OK\n",
      "Date: Sat, 06 Apr 2019 11:46:26 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Last-Modified: Mon, 15 May 2017 12:27:40 GMT\n",
      "ETag: \"38342-54f8f2e5b6277\"\n",
      "Accept-Ranges: bytes\n",
      "Content-Length: 230210\n",
      "Vary: Accept-Encoding\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\n",
      "Pragma: no-cache\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\n",
      "Connection: close\n",
      "Content-Type: image/jpeg\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import time\n",
    "\n",
    "HOST = 'data.pr4e.org'\n",
    "PORT = 80\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect((HOST, PORT))\n",
    "mysock.sendall(b'GET http://data.pr4e.org/cover3.jpg HTTP/1.0\\r\\n\\r\\n')\n",
    "count = 0\n",
    "picture = b\"\"\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(5120)\n",
    "    if len(data) < 1: break\n",
    "    #time.sleep(0.25)\n",
    "    count = count + len(data)\n",
    "    print(len(data), count)\n",
    "    picture = picture + data\n",
    "\n",
    "mysock.close()\n",
    "\n",
    "# Look for the end of the header (2 CRLF)\n",
    "pos = picture.find(b\"\\r\\n\\r\\n\")\n",
    "print('Header length', pos)\n",
    "print(picture[:pos].decode())\n",
    "\n",
    "# Skip past the header and save the picture data\n",
    "picture = picture[pos+4:]\n",
    "fhand = open(\"stuff.jpg\", \"wb\")\n",
    "fhand.write(picture)\n",
    "fhand.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.4 Retrieving web pages with urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'But': 1, 'soft': 1, 'what': 1, 'light': 1, 'through': 1, 'yonder': 1, 'window': 1, 'breaks': 1, 'It': 1, 'is': 3, 'the': 3, 'east': 1, 'and': 3, 'Juliet': 1, 'sun': 2, 'Arise': 1, 'fair': 1, 'kill': 1, 'envious': 1, 'moon': 1, 'Who': 1, 'already': 1, 'sick': 1, 'pale': 1, 'with': 1, 'grief': 1}\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "counts = dict()\n",
    "for line in fhand:\n",
    "    words = line.decode().split()\n",
    "    for word in words:\n",
    "        counts[word] = counts.get(word, 0) + 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.6 Parsing HTML using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter - http://www.dr-chuck.com/page1.htm\n",
      "http://www.dr-chuck.com/page2.htm\n"
     ]
    }
   ],
   "source": [
    "# Search for lines that start with From and have an at sign\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import re\n",
    "\n",
    "url = input('Enter - ')\n",
    "html = urllib.request.urlopen(url).read()\n",
    "links = re.findall(b'href=\"(http://.*?)\"', html)\n",
    "for link in links:\n",
    "    print(link.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.7 Parsing HTML using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this, you can install BeautifulSoup\n",
    "# https://pypi.python.org/pypi/beautifulsoup4\n",
    "\n",
    "# Or download the file\n",
    "# http://www.py4e.com/code3/bs4.zip\n",
    "# and unzip it in the same directory as this file\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ')\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "    print(tag.get('href', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this, you can install BeautifulSoup\n",
    "# https://pypi.python.org/pypi/beautifulsoup4\n",
    "\n",
    "# Or download the file\n",
    "# http://www.py4e.com/code3/bs4.zip\n",
    "# and unzip it in the same directory as this file\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ')\n",
    "html = urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "    # Look at the parts of a tag\n",
    "    print('TAG:', tag)\n",
    "    print('URL:', tag.get('href', None))\n",
    "    print('Contents:', tag.contents[0])\n",
    "    print('Attrs:', tag.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.8 Reading binary files using urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "img = urllib.request.urlopen('http://data.pr4e.org/cover3.jpg').read()\n",
    "fhand = open('cover3.jpg', 'wb')\n",
    "fhand.write(img)\n",
    "fhand.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230210 characters copied.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "img = urllib.request.urlopen('http://data.pr4e.org/cover3.jpg')\n",
    "fhand = open('cover3.jpg', 'wb')\n",
    "size = 0\n",
    "while True:\n",
    "    info = img.read(100000)\n",
    "    if len(info) < 1: break\n",
    "    size = size + len(info)\n",
    "    fhand.write(info)\n",
    "\n",
    "print(size, 'characters copied.')\n",
    "fhand.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
